{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'genres', 'original_language', 'popularity',\n",
       "       'production_companies', 'production_countries', 'release_date',\n",
       "       'revenue', 'runtime', 'vote_average', 'vote_count', 'popularity_norm',\n",
       "       'year', 'month', 'date', 'quarter', 'others', 'en', 'fr', 'ru', 'es',\n",
       "       'hi', 'ja', 'it', 'ko', 'cn', 'zh'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'popularity', 'revenue', 'runtime', 'vote_average',\n",
       "       'vote_count', 'quarter', 'en'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3169"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('ver1.csv', index_col=['id'])\n",
    "display(df.columns)\n",
    "df.drop(columns=['production_countries', 'production_companies', 'genres', 'release_date', \n",
    "                 'popularity_norm', 'year', 'original_language', 'fr', 'ru', 'es', 'hi', \n",
    "                 'ja', 'it', 'ko', 'cn', 'zh', 'others', 'month', 'date'], inplace=True)\n",
    "\n",
    "# col_norm = ['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count', 'popularity_norm']\n",
    "\n",
    "df_norm = df\n",
    "display(df_norm.columns)\n",
    "# df_norm[col_norm] = (df_norm[col_norm] - df_norm[col_norm].mean()) / df_norm[col_norm].std()\n",
    "df_norm_mean = df_norm.mean()\n",
    "df_norm_std = df_norm.std()\n",
    "df_norm = (df_norm - df_norm_mean) / df_norm_std\n",
    "\n",
    "# display(df_norm[df_norm.isna().any(axis=1)])\n",
    "display(len(df_norm.columns), len(df_norm))\n",
    "\n",
    "X_train, X_test = train_test_split(df_norm, test_size = 0.2, random_state=1)\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train)\n",
    "y_train = X_train[['revenue']]\n",
    "X_train = X_train.drop(columns=['revenue'])\n",
    "X_test = pd.DataFrame(data=X_test)\n",
    "y_test = X_test[['revenue']]\n",
    "X_test = X_test.drop(columns=['revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>quarter</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12160</td>\n",
       "      <td>0.487400</td>\n",
       "      <td>-0.430745</td>\n",
       "      <td>3.818361</td>\n",
       "      <td>0.213421</td>\n",
       "      <td>-0.557498</td>\n",
       "      <td>-0.581184</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>-0.815018</td>\n",
       "      <td>-0.571277</td>\n",
       "      <td>-0.567772</td>\n",
       "      <td>0.790005</td>\n",
       "      <td>-0.492792</td>\n",
       "      <td>0.336033</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214756</td>\n",
       "      <td>0.599677</td>\n",
       "      <td>1.079609</td>\n",
       "      <td>0.195034</td>\n",
       "      <td>-0.132529</td>\n",
       "      <td>1.032712</td>\n",
       "      <td>-0.581184</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7942</td>\n",
       "      <td>-0.702740</td>\n",
       "      <td>-0.401954</td>\n",
       "      <td>-0.520096</td>\n",
       "      <td>-0.132529</td>\n",
       "      <td>-0.532178</td>\n",
       "      <td>0.336033</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112949</td>\n",
       "      <td>-0.298542</td>\n",
       "      <td>0.226233</td>\n",
       "      <td>0.195034</td>\n",
       "      <td>0.674688</td>\n",
       "      <td>-0.120735</td>\n",
       "      <td>-1.498402</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109091</td>\n",
       "      <td>-0.365908</td>\n",
       "      <td>0.151726</td>\n",
       "      <td>0.290385</td>\n",
       "      <td>-1.516329</td>\n",
       "      <td>-0.198804</td>\n",
       "      <td>1.253251</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7516</td>\n",
       "      <td>-0.545552</td>\n",
       "      <td>-0.165621</td>\n",
       "      <td>-0.091018</td>\n",
       "      <td>0.098105</td>\n",
       "      <td>-0.323995</td>\n",
       "      <td>1.253251</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9353</td>\n",
       "      <td>-0.208720</td>\n",
       "      <td>-0.409201</td>\n",
       "      <td>-0.901499</td>\n",
       "      <td>-0.824429</td>\n",
       "      <td>-0.447076</td>\n",
       "      <td>-0.581184</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>0.195479</td>\n",
       "      <td>0.094091</td>\n",
       "      <td>0.671788</td>\n",
       "      <td>-0.017212</td>\n",
       "      <td>0.050876</td>\n",
       "      <td>-0.581184</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9257</td>\n",
       "      <td>0.869143</td>\n",
       "      <td>0.125034</td>\n",
       "      <td>0.290385</td>\n",
       "      <td>-0.593795</td>\n",
       "      <td>-0.158011</td>\n",
       "      <td>0.336033</td>\n",
       "      <td>0.199213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2535 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          budget  popularity   runtime  vote_average  vote_count   quarter  \\\n",
       "id                                                                           \n",
       "12160   0.487400   -0.430745  3.818361      0.213421   -0.557498 -0.581184   \n",
       "1024   -0.815018   -0.571277 -0.567772      0.790005   -0.492792  0.336033   \n",
       "214756  0.599677    1.079609  0.195034     -0.132529    1.032712 -0.581184   \n",
       "7942   -0.702740   -0.401954 -0.520096     -0.132529   -0.532178  0.336033   \n",
       "112949 -0.298542    0.226233  0.195034      0.674688   -0.120735 -1.498402   \n",
       "...          ...         ...       ...           ...         ...       ...   \n",
       "109091 -0.365908    0.151726  0.290385     -1.516329   -0.198804  1.253251   \n",
       "7516   -0.545552   -0.165621 -0.091018      0.098105   -0.323995  1.253251   \n",
       "9353   -0.208720   -0.409201 -0.901499     -0.824429   -0.447076 -0.581184   \n",
       "588     0.195479    0.094091  0.671788     -0.017212    0.050876 -0.581184   \n",
       "9257    0.869143    0.125034  0.290385     -0.593795   -0.158011  0.336033   \n",
       "\n",
       "              en  \n",
       "id                \n",
       "12160   0.199213  \n",
       "1024    0.199213  \n",
       "214756  0.199213  \n",
       "7942    0.199213  \n",
       "112949  0.199213  \n",
       "...          ...  \n",
       "109091  0.199213  \n",
       "7516    0.199213  \n",
       "9353    0.199213  \n",
       "588     0.199213  \n",
       "9257    0.199213  \n",
       "\n",
       "[2535 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kmeans = KMeans(n_clusters=10)\n",
    "# cluster_predict = kmeans.fit_predict(X_train)\n",
    "# display(X_train, cluster_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The explained variance is:\n",
      "[0.34701968 0.19044155 0.14142852 0.11671884 0.11417898]\n",
      "\n",
      "In 1st PCA axis, the ordering of columns in descending order:\n",
      "Index(['vote_count', 'popularity', 'budget', 'runtime', 'vote_average',\n",
      "       'quarter', 'en'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "np_pca = pca.fit_transform(X_train)\n",
    "print(f'The explained variance is:\\n{pca.explained_variance_ratio_}\\n')\n",
    "# display(pca.components_)\n",
    "# display(np.sort(pca.components_[0])[::-1])\n",
    "# display(pca.components_[0].argsort()[::-1])\n",
    "print(f'In 1st PCA axis, the ordering of columns in descending order:\\n{X_train.columns[pca.components_[0].argsort()[::-1]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA + KMeans\n",
    "\n",
    "1. Get PCA with `n_components = 5`\n",
    "2. Do KMeans Training with `k = 2, 3, ..., 10`\n",
    "3. (Optional) Do Meta Learning on the KMeans output vs the actual revenue class\n",
    "4. Plot the scatter graph of KMeans clustering and the result of Binning the Revenue column (the larger/brighter the label, the higher the revenue)\n",
    "5. Validate the result with test data (`test_split = 0.2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # see the difference with different K without ensemble learning on training data\n",
    "\n",
    "# pca = PCA(n_components=5)\n",
    "# np_pca = pca.fit_transform(X_train)\n",
    "# display(pca.explained_variance_ratio_)\n",
    "# fig, axs = plt.subplots(max_k - 1, 2, figsize=(14, 30))\n",
    "# plt.subplots_adjust(hspace=0.4, wspace=0.1)\n",
    "\n",
    "# for i in range(2, max_k + 1):\n",
    "#     kmeans = KMeans(n_clusters=i, random_state=1)\n",
    "#     cluster_predict = kmeans.fit_predict(X_train)\n",
    "\n",
    "#     df_pca = pd.DataFrame(data=np_pca[:, :2], columns=['pca_1st_col', 'pca_2nd_col'], index=X_train.index)\n",
    "    \n",
    "#     df_pca['revenue'] = y_train['revenue']\n",
    "#     df_pca['revenue_bin'] = pd.qcut(y_train['revenue'], i)\n",
    "#     df_pca['revenue_bin_label'] = pd.qcut(y_train['revenue'], i, labels=[*range(i)])\n",
    "#     df_pca['cluster'] = cluster_predict    \n",
    "   \n",
    "#     axs[i-2, 0].set_ylabel('PCA 2nd component')\n",
    "#     axs[i-2, 0].set_xlabel('PCA 1st component')\n",
    "#     axs[i-2, 0].set_title(f'Kmeans with K = {i}')\n",
    "#     f1 = axs[i-2, 0].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['cluster'], cmap='viridis')\n",
    "#     fig.colorbar(f1, ax=axs[i-2, 0])\n",
    "\n",
    "\n",
    "#     axs[i-2, 1].set_ylabel('PCA 2nd component')\n",
    "#     axs[i-2, 1].set_xlabel('PCA 1st component')\n",
    "#     axs[i-2, 1].set_title(f'Revenue Quantile Bin = {i}')\n",
    "#     f2 = axs[i-2, 1].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['revenue_bin_label'], cmap='viridis')\n",
    "#     fig.colorbar(f2, ax=axs[i-2, 1])\n",
    "    \n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34701968, 0.19044155, 0.14142852, 0.11671884, 0.11417898])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see the difference with different K with ensemble learning of 200 KMeans model on training data\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "np_pca = pca.fit_transform(X_train)\n",
    "display(pca.explained_variance_ratio_)\n",
    "fig, axs = plt.subplots(max_k - 1, 2, figsize=(14, 30))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.1)\n",
    "\n",
    "models_store = {\n",
    "    'pca': pca,\n",
    "    'kmeans': [],\n",
    "    'dt': [],\n",
    "    'bins': [],\n",
    "    'ensemble_dt': [],\n",
    "}\n",
    "\n",
    "train_data_save = {\n",
    "    'y_train': [],\n",
    "    'X_train': [],\n",
    "}\n",
    "\n",
    "ensemble_num = 100\n",
    "\n",
    "for i in range(2, max_k + 1):\n",
    "# for i in range(2, 3):\n",
    "    kmeans = [KMeans(n_clusters=i, random_state=j) for j in range(ensemble_num)]\n",
    "    cluster_predict = np.array([kmeans[j].fit_predict(X_train) for j in range(ensemble_num)]).T\n",
    "    \n",
    "    models_store['kmeans'].append(kmeans)\n",
    "\n",
    "    df_pca = pd.DataFrame(data=np_pca[:, :2], columns=['pca_1st_col', 'pca_2nd_col'], index=X_train.index)\n",
    "    \n",
    "    df_pca['revenue'] = y_train['revenue']\n",
    "    ser, bins = pd.qcut(y_train['revenue'], i, retbins=True, labels=[*range(i)])\n",
    "    df_pca['revenue_bin_label'] = ser\n",
    "    df_pca['cluster'] = cluster_predict.tolist()\n",
    "    \n",
    "    models_store['bins'].append(bins)\n",
    "    \n",
    "    # predict cluster actual label\n",
    "    y_true_np = df_pca[['revenue_bin_label']].to_numpy()\n",
    "    clf = [DecisionTreeClassifier(max_depth=1, random_state=j) for j in range(ensemble_num)]\n",
    "    clf = [clf[dt].fit(cluster_predict[:, dt].reshape(-1, 1), y_true_np) for dt in range(len(clf))]\n",
    "    models_store['dt'].append(clf)\n",
    "    \n",
    "    cluster_2nd_predict = [clf[dt].predict(cluster_predict[:, dt].reshape(-1, 1)) for dt in range(len(clf))]\n",
    "    cluster_2nd_predict = np.array(cluster_2nd_predict).T\n",
    "#     display(cluster_2nd_predict)\n",
    "    \n",
    "    ensemble_dt = DecisionTreeClassifier(random_state=1)\n",
    "    ensemble_dt.fit(cluster_2nd_predict, y_true_np)\n",
    "    models_store['ensemble_dt'].append(ensemble_dt)\n",
    "    \n",
    "    df_pca['cluster_pred'] = ensemble_dt.predict(cluster_2nd_predict)\n",
    "    train_data_save['y_train'].append(y_true_np)\n",
    "    train_data_save['X_train'].append(cluster_2nd_predict)\n",
    "    \n",
    "    axs[i-2, 0].set_ylabel('PCA 2nd component')\n",
    "    axs[i-2, 0].set_xlabel('PCA 1st component')\n",
    "    axs[i-2, 0].set_title(f'Kmeans with K = {i}')\n",
    "    f1 = axs[i-2, 0].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['cluster_pred'], cmap='viridis')\n",
    "    fig.colorbar(f1, ax=axs[i-2, 0])\n",
    "\n",
    "    axs[i-2, 1].set_ylabel('PCA 2nd component')\n",
    "    axs[i-2, 1].set_xlabel('PCA 1st component')\n",
    "    axs[i-2, 1].set_title(f'Revenue Quantile Bin = {i}')\n",
    "    f2 = axs[i-2, 1].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['revenue_bin_label'], cmap='viridis')\n",
    "    fig.colorbar(f2, ax=axs[i-2, 1])\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # see the difference with different K with meta learning on training data\n",
    "\n",
    "# pca = PCA(n_components=5)\n",
    "# np_pca = pca.fit_transform(X_train)\n",
    "# display(pca.explained_variance_ratio_)\n",
    "# fig, axs = plt.subplots(max_k - 1, 2, figsize=(14, 30))\n",
    "# plt.subplots_adjust(hspace=0.4, wspace=0.1)\n",
    "\n",
    "# models_store = {\n",
    "#     'pca': pca,\n",
    "#     'kmeans': [],\n",
    "#     'dt': [],\n",
    "#     'bins': [],\n",
    "# }\n",
    "\n",
    "# train_data_save = {\n",
    "#     'y_train': [],\n",
    "#     'X_train': [],\n",
    "# }\n",
    "\n",
    "# for i in range(2, max_k + 1):\n",
    "#     kmeans = KMeans(n_clusters=i, random_state=1)\n",
    "#     cluster_predict = kmeans.fit_predict(X_train)\n",
    "    \n",
    "#     models_store['kmeans'].append(kmeans)\n",
    "\n",
    "#     df_pca = pd.DataFrame(data=np_pca[:, :2], columns=['pca_1st_col', 'pca_2nd_col'], index=X_train.index)\n",
    "    \n",
    "#     df_pca['revenue'] = y_train['revenue']\n",
    "#     ser, bins = pd.qcut(y_train['revenue'], i, retbins=True, labels=[*range(i)])\n",
    "#     df_pca['revenue_bin_label'] = ser\n",
    "#     df_pca['cluster'] = cluster_predict\n",
    "    \n",
    "#     models_store['bins'].append(bins)\n",
    "\n",
    "#     # predict cluster actual label\n",
    "#     clf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "#     clf.fit(df_pca[['cluster']], df_pca[['revenue_bin_label']])\n",
    "#     df_pca['cluster_pred'] = clf.predict(df_pca[['cluster']])\n",
    "#     train_data_save['y_train'].append(df_pca[['revenue_bin_label']])\n",
    "#     train_data_save['X_train'].append(df_pca[['cluster']])\n",
    "#     models_store['dt'].append(clf)\n",
    "   \n",
    "#     axs[i-2, 0].set_ylabel('PCA 2nd component')\n",
    "#     axs[i-2, 0].set_xlabel('PCA 1st component')\n",
    "#     axs[i-2, 0].set_title(f'Kmeans with K = {i}')\n",
    "#     f1 = axs[i-2, 0].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['cluster_pred'], cmap='viridis')\n",
    "#     fig.colorbar(f1, ax=axs[i-2, 0])\n",
    "\n",
    "#     axs[i-2, 1].set_ylabel('PCA 2nd component')\n",
    "#     axs[i-2, 1].set_xlabel('PCA 1st component')\n",
    "#     axs[i-2, 1].set_title(f'Revenue Quantile Bin = {i}')\n",
    "#     f2 = axs[i-2, 1].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['revenue_bin_label'], cmap='viridis')\n",
    "#     fig.colorbar(f2, ax=axs[i-2, 1])\n",
    "    \n",
    "    \n",
    "    \n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the difference with different K with ensemble learning on testing data\n",
    "\n",
    "pca = models_store['pca']\n",
    "np_pca = pca.transform(X_test)\n",
    "display(pca.explained_variance_ratio_)\n",
    "fig, axs = plt.subplots(max_k - 1, 2, figsize=(14, 30))\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.1)\n",
    "\n",
    "test_data_save = {\n",
    "    'y_pred': [],\n",
    "    'y_true': [],\n",
    "}\n",
    "\n",
    "for i in range(2, max_k + 1):\n",
    "# for i in range(2, 3):\n",
    "    kmeans = models_store['kmeans'][i - 2]\n",
    "    cluster_predict = np.array([clf.predict(X_test) for clf in kmeans]).T\n",
    "    \n",
    "    df_pca = pd.DataFrame(data=np_pca[:, :2], columns=['pca_1st_col', 'pca_2nd_col'], index=X_test.index)\n",
    "    \n",
    "    df_pca['revenue'] = y_test['revenue']\n",
    "    bins = models_store['bins'][i - 2]\n",
    "    ser = pd.cut(y_test['revenue'], bins=bins, labels=[*range(i)])\n",
    "    df_pca['revenue_bin_label'] = ser\n",
    "    df_pca['cluster'] = cluster_predict.tolist()\n",
    "    \n",
    "    test_data_save['y_pred'].append(cluster_predict)\n",
    "    test_data_save['y_true'].append(ser)\n",
    "\n",
    "    # predict cluster actual label\n",
    "    clf = models_store['dt'][i - 2]\n",
    "    cluster_2nd_predict = np.array([clf[dt].predict(cluster_predict[:, dt].reshape(-1, 1)) for dt in range(len(clf))]).T\n",
    "#     display(cluster_2nd_predict, cluster_2nd_predict.shape)\n",
    "    \n",
    "    ensemble_dt = models_store['ensemble_dt'][i - 2]\n",
    "    df_pca['cluster_pred'] = ensemble_dt.predict(cluster_2nd_predict)\n",
    "   \n",
    "    axs[i-2, 0].set_ylabel('PCA 2nd component')\n",
    "    axs[i-2, 0].set_xlabel('PCA 1st component')\n",
    "    axs[i-2, 0].set_title(f'Kmeans with K = {i}')\n",
    "    f1 = axs[i-2, 0].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['cluster_pred'], cmap='viridis')\n",
    "    fig.colorbar(f1, ax=axs[i-2, 0])\n",
    "\n",
    "\n",
    "    axs[i-2, 1].set_ylabel('PCA 2nd component')\n",
    "    axs[i-2, 1].set_xlabel('PCA 1st component')\n",
    "    axs[i-2, 1].set_title(f'Revenue Quantile Bin = {i}')\n",
    "    f2 = axs[i-2, 1].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['revenue_bin_label'], cmap='viridis')\n",
    "    fig.colorbar(f2, ax=axs[i-2, 1])\n",
    "    \n",
    "    \n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # see the difference with different K with meta learning on testing data\n",
    "\n",
    "# pca = models_store['pca']\n",
    "# np_pca = pca.transform(X_test)\n",
    "# display(pca.explained_variance_ratio_)\n",
    "# fig, axs = plt.subplots(max_k - 1, 2, figsize=(14, 30))\n",
    "# plt.subplots_adjust(hspace=0.4, wspace=0.1)\n",
    "\n",
    "# test_data_save = {\n",
    "#     'y_pred': [],\n",
    "#     'y_true': [],\n",
    "# }\n",
    "\n",
    "# for i in range(2, max_k + 1):\n",
    "#     kmeans = models_store['kmeans'][i - 2]\n",
    "#     cluster_predict = kmeans.predict(X_test)\n",
    "    \n",
    "#     df_pca = pd.DataFrame(data=np_pca[:, :2], columns=['pca_1st_col', 'pca_2nd_col'], index=X_test.index)\n",
    "    \n",
    "#     df_pca['revenue'] = y_test['revenue']\n",
    "#     bins = models_store['bins'][i - 2]\n",
    "#     ser = pd.cut(y_test['revenue'], bins=bins, labels=[*range(i)])\n",
    "#     df_pca['revenue_bin_label'] = ser\n",
    "#     df_pca['cluster'] = cluster_predict\n",
    "    \n",
    "#     test_data_save['y_pred'].append(cluster_predict)\n",
    "#     test_data_save['y_true'].append(ser)\n",
    "        \n",
    "#     # predict cluster actual label\n",
    "#     clf = models_store['dt'][i - 2]\n",
    "#     df_pca['cluster_pred'] = clf.predict(df_pca[['cluster']])\n",
    "   \n",
    "#     axs[i-2, 0].set_ylabel('PCA 2nd component')\n",
    "#     axs[i-2, 0].set_xlabel('PCA 1st component')\n",
    "#     axs[i-2, 0].set_title(f'Kmeans with K = {i}')\n",
    "#     f1 = axs[i-2, 0].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['cluster_pred'], cmap='viridis')\n",
    "#     fig.colorbar(f1, ax=axs[i-2, 0])\n",
    "\n",
    "\n",
    "#     axs[i-2, 1].set_ylabel('PCA 2nd component')\n",
    "#     axs[i-2, 1].set_xlabel('PCA 1st component')\n",
    "#     axs[i-2, 1].set_title(f'Revenue Quantile Bin = {i}')\n",
    "#     f2 = axs[i-2, 1].scatter(df_pca['pca_1st_col'], df_pca['pca_2nd_col'], c=df_pca['revenue_bin_label'], cmap='viridis')\n",
    "#     fig.colorbar(f2, ax=axs[i-2, 1])\n",
    "    \n",
    "    \n",
    "    \n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(14, 20))\n",
    "\n",
    "for k in range(2, max_k + 1):\n",
    "    n_classes = k\n",
    "    \n",
    "    y_test_evaluate = np.array(test_data_save['y_true'][k - 2]).reshape(-1, 1)\n",
    "    y_train_evaluate = np.array(train_data_save['y_train'][k - 2]).reshape(-1, 1)\n",
    "    y_train_evaluate_len = len(y_train_evaluate)\n",
    "    y_test_evaluate_len = len(y_test_evaluate)\n",
    "    X_train_evaluate = np.array(train_data_save['X_train'][k - 2])\n",
    "    X_test_evaluate = np.array(test_data_save['y_pred'][k - 2])\n",
    "    \n",
    "#     display(X_test_evaluate, X_test_evaluate.shape)\n",
    "#     display(X_train_evaluate, X_train_evaluate.shape, y_train_evaluate.shape)\n",
    "\n",
    "    if k == 2:\n",
    "        y_test_evaluate = label_binarize(y_test_evaluate, classes=[0, 1, 2])\n",
    "    else:\n",
    "        y_test_evaluate = label_binarize(y_test_evaluate, classes=[*range(k)])\n",
    "\n",
    "    # classifier\n",
    "    clf = OneVsRestClassifier(estimator=models_store['ensemble_dt'][k - 2])\n",
    "    display(X_train_evaluate, X_train_evaluate.shape, y_train_evaluate, y_train_evaluate.shape, X_test_evaluate, X_test_evaluate.shape)\n",
    "    display(np.isfinite(X_train_evaluate).all(), np.isfinite(y_train_evaluate).all(), np.isfinite(X_test_evaluate).all())\n",
    "    y_score_evaluate = clf.fit(X_train_evaluate, y_train_evaluate).predict_proba(X_test_evaluate)\n",
    "    display(np.argwhere(np.isnan(y_score_evaluate)))\n",
    "    display(X_train_evaluate[50:55, :], y_train_evaluate[50:55, :], X_test_evaluate[50:55, ], y_score_evaluate[50:55, ])\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        display(y_test_evaluate.shape, y_score_evaluate.shape)\n",
    "        display(np.isfinite(y_test_evaluate).all(), np.isfinite(y_score_evaluate).all())\n",
    "        display(y_score_evaluate[~np.isfinite(y_score_evaluate)])\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_evaluate[:, i], y_score_evaluate[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot of a ROC curve for a specific class\n",
    "    for i in range(n_classes):\n",
    "        axs[int((k - 2) / 3), (k - 2) % 3].plot(fpr[i], tpr[i], label=f'Label {i} (area = {roc_auc[i]:0.2f})')\n",
    "        axs[int((k - 2) / 3), (k - 2) % 3].plot([0, 1], [0, 1], 'k--')\n",
    "        axs[int((k - 2) / 3), (k - 2) % 3].axis(xlim=[0.0, 1.0], ylim=[0.0, 1.05])\n",
    "        axs[int((k - 2) / 3), (k - 2) % 3].set_xlabel('False Positive Rate')\n",
    "        axs[int((k - 2) / 3), (k - 2) % 3].set_ylabel('True Positive Rate')\n",
    "        axs[int((k - 2) / 3), (k - 2) % 3].set_title(f'ROC for k = {k}')\n",
    "        axs[int((k - 2) / 3), (k - 2) % 3].legend(loc=\"lower right\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "%precision %.2f\n",
    "k_10 = models_store['kmeans'][8]\n",
    "# display(k_10.cluster_centers_)\n",
    "\n",
    "dotfile = open(\"dt_10.dot\", 'w')\n",
    "dt_10 = models_store['dt'][8]\n",
    "high_revenue_cluster_center = k_10.cluster_centers_[9]\n",
    "# display(high_revenue_cluster_center)\n",
    "# display(df_norm.columns)\n",
    "# df_col = df_norm.columns.drop('revenue')\n",
    "# df_norm = (df_norm - df_norm_mean) / df_norm_std\n",
    "cluster_norm_df = pd.DataFrame(data=[high_revenue_cluster_center], columns=df_norm.columns.drop('revenue'))\n",
    "cluster_df = cluster_norm_df * df_norm_std + df_norm_mean\n",
    "cluster_df = cluster_df[df_norm.columns.drop('revenue')]\n",
    "cluster_df = cluster_df.transpose().round(2)\n",
    "cluster_df = cluster_df.rename(columns={0: 'k = 10, label = 9 (max in 0-based index)'})\n",
    "with pd.option_context('display.float_format', '{:,.2f}'.format):\n",
    "    display(cluster_df)\n",
    "\n",
    "# Source(export_graphviz(dt_10, out_file=None, feature_names=['cluster_label'], class_names=[str(x) for x in range(10)]))\n",
    "\n",
    "k_10_budget = cluster_df.loc['budget', :][0]\n",
    "revenue_np_array = np.array(df['revenue'].reset_index(drop=True))\n",
    "revenue_np_array = np.append(revenue_np_array, k_10_budget)\n",
    "revenue_np_array_argsort = revenue_np_array.argsort()\n",
    "k_10_budget_percentile = revenue_np_array_argsort[-1] / np.max(revenue_np_array_argsort)\n",
    "# display(revenue_np_array_argsort[-1], np.max(revenue_np_array_argsort))\n",
    "print(f'The percentile of the budget is {round(k_10_budget_percentile, 2)} for budget {k_10_budget:,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "y_true = np.array(test_data_save['y_true'][10 - 2]).reshape(-1, 1)\n",
    "y_pred = np.array(test_data_save['y_pred'][10 - 2]).reshape(-1, 1)\n",
    "\n",
    "display(multilabel_confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insight\n",
    "\n",
    "1. Using higher K and binning, could be able to predict higher revenue movie\n",
    "2. Since data is not large enough, by having more data from various classes and backgrounds, the prediction could be more accurate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
